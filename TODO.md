# Game-News-Express 專案待辦事項

此文件記錄了專案在經過初步審查後，需要執行的主要改善任務，以確保專案的品質、穩定性與可維護性。

## 優先事項 (P0 - Critical)

### 1. 建立完整的測試策略
- **問題**: `tests` 目錄為空，完全沒有測試，嚴重違反「測試覆蓋率 ≥ 80%」的規範。
- **解決方案**:
    - [ ] **設定測試環境**: 引入並設定 `Jest` 與 `React Testing Library` 用於單元／整合測試。
    - [ ] **設定 E2E 測試**: 引入並設定 `Playwright` 進行端對端測試。
    - [ ] **撰寫測試案例**:
        - [ ] 為 `src/lib` 中的核心邏輯（如 `crawler.ts`, `supabase.ts`）編寫單元測試。
        - [ ] 為 API 路由編寫整合測試。
        - [ ] 為關鍵使用者流程（如查看遊戲新聞）編寫 E2E 測試。
    - [ ] **目標**: 逐步將測試覆蓋率提升至 80% 以上。

### 2. 重構資料庫毀滅性操作
- **問題**: 爬蟲腳本 (`crawler.ts` 和 `run-bluearchive-crawler.js`) 在執行前會清除整個資料表，此為高風險操作且違反規範。
- **解決方案**:
    - [ ] **移除自動刪除邏輯**: 從爬蟲腳本中移除 `clearDatabase()` 或 `delete()` 的自動呼叫。
    - [ ] **改用 Upsert 邏輯**:
        - 利用 Supabase 提供的 `upsert` 功能，根據唯一的文章 URL 或 ID 來「更新或插入」新聞資料。
        - 這能確保資料的冪等性，避免重複執行時造成資料遺失。
    - [ ] **建立獨立的清理腳本**: 若仍需清空資料庫，應將其做成一個獨立、需手動執行的腳本，並在執行前加上明確的警告與確認步驟。

### 3. 修正並重構「蔚藍檔案」爬蟲
- **問題**: `scripts/run-bluearchive-crawler.js` 目前是寫死的，只能處理單一 URL，並非一個真正的爬蟲。
- **解決方案**:
    - [ ] **實現動態爬取**: 重寫此腳本，使其能：
        - 1. 訪問《蔚藍檔案》官方公告列表頁。
        - 2. 獲取所有公告的標題與連結。
        - 3. 遍歷連結，進入每一則公告的詳細頁面抓取完整內容。
    - [ ] **統一爬蟲邏輯**: 沿用 `upsert` 邏輯來儲存資料。

## 改善事項 (P1 - Improvement)

### 4. 統一與整理腳本
- **問題**: 專案同時存在根目錄的 `scripts` (JavaScript) 和 `src/scripts` (TypeScript)，架構混亂。
- **解決方案**:
    - [ ] **遷移腳本**: 將所有腳本統一移至根目錄的 `scripts` 資料夾。
    - [ ] **統一語言**: 建議將所有腳本統一為 TypeScript，並使用 `ts-node` 執行，以利用型別檢查的優勢。

### 5. 提升程式碼品質
- **問題**: 部分程式碼，尤其是爬蟲腳本，缺乏註解，且函式過於龐大，不易維護。
- **解決方案**:
    - [ ] **增加註解**: 為複雜的邏輯區塊（如 `run-bluearchive-crawler.js` 中的內容分段與分析邏輯）添加清晰的註解。
    - [ ] **重構長函式**: 將超過 50 行的複雜函式（如 `crawlNews`）拆分為更小、單一職責的輔助函式。 